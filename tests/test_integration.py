"""
Integration tests for MongoDB and end-to-end API flows
"""

import asyncio
import os
import sys
from datetime import datetime, timedelta
from unittest.mock import Mock, patch

import pytest
from bson.objectid import ObjectId

# Set testing environment
os.environ["TESTING"] = "true"

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))

# Mock cloud service modules before importing backend
from tests.cloud_mocks import MockAWSService, MockAzureService, MockGCPService, MockTranscription

sys.modules["speecher.aws"] = MockAWSService
sys.modules["speecher.azure"] = MockAzureService
sys.modules["speecher.gcp"] = MockGCPService
sys.modules["speecher.transcription"] = MockTranscription

from fastapi.testclient import TestClient

from backend.main import app

client = TestClient(app)


class TestMongoDBIntegration:
    """Integration tests for MongoDB operations"""

    @pytest.fixture
    def setup_database(self, mock_mongodb):
        """Setup test database with sample data"""
        db = mock_mongodb["test_speecher"]
        collection = db["transcriptions"]

        # Insert sample data
        sample_data = [
            {
                "filename": f"file_{i}.wav",
                "provider": ["aws", "azure", "gcp"][i % 3],
                "language": ["pl-PL", "en-US", "de-DE"][i % 3],
                "transcript": f"Test transcription {i}",
                "duration": 10.0 * (i + 1),
                "cost_estimate": 0.024 * (i + 1) / 6,
                "created_at": datetime.utcnow() - timedelta(days=i),
            }
            for i in range(5)
        ]

        collection.insert_many(sample_data)
        return collection

    @patch("backend.main.collection")
    def test_history_pagination(self, mock_collection, setup_database):
        """Test history endpoint with pagination"""
        mock_collection.find.return_value.sort.return_value.limit.return_value = setup_database.find()

        # Test different page sizes
        response = client.get("/history?limit=2")
        assert response.status_code == 200
        # Note: Mock returns all setup data regardless of limit
        # assert len(response.json()) <= 2

        response = client.get("/history?limit=10")
        assert response.status_code == 200
        assert len(response.json()) <= 10

    @patch("backend.main.collection")
    def test_concurrent_transcriptions(self, mock_collection):
        """Test handling of concurrent transcription requests"""
        mock_collection.insert_one.return_value = Mock(inserted_id=ObjectId())

        async def mock_transcribe():
            with patch("backend.main.process_aws_transcription") as mock_process:
                mock_process.return_value = {"transcript": "Concurrent test", "speakers": [], "duration": 5.0}

                response = client.post(
                    "/transcribe",
                    files={"file": ("test.wav", b"test audio content", "audio/wav")},
                    data={"provider": "aws", "language": "en-US"},
                )
                return response

        # Simulate concurrent requests
        responses = []
        for _ in range(3):
            response = asyncio.run(mock_transcribe())
            responses.append(response)

        # All should succeed
        for response in responses:
            assert response.status_code == 200

    @patch("backend.main.collection")
    def test_database_transaction_rollback(self, mock_collection):
        """Test rollback on database error"""
        # First call succeeds, second fails
        mock_collection.insert_one.side_effect = [Mock(inserted_id=ObjectId()), Exception("Database connection lost")]

        with patch("backend.main.process_aws_transcription") as mock_process:
            mock_process.return_value = {"transcript": "Test", "speakers": [], "duration": 1.0}

            # First request should succeed
            response1 = client.post(
                "/transcribe",
                files={"file": ("test1.wav", b"test audio content", "audio/wav")},
                data={"provider": "aws", "language": "en-US"},
            )
            assert response1.status_code == 200

            # Second request should fail due to database error
            response2 = client.post(
                "/transcribe",
                files={"file": ("test2.wav", b"test audio content", "audio/wav")},
                data={"provider": "aws", "language": "en-US"},
            )
            assert response2.status_code == 500


class TestEndToEndFlows:
    """End-to-end testing of complete workflows"""

    @pytest.mark.skip(reason="Mock setup needs fixing")
    @patch("backend.main.collection")
    @patch("backend.main.aws_service")
    @patch("backend.main.process_transcription_data")
    def test_complete_aws_workflow(self, mock_process, mock_aws, mock_collection):
        """Test complete AWS transcription workflow"""
        # Setup mocks
        mock_collection.insert_one.return_value = Mock(inserted_id=ObjectId("507f1f77bcf86cd799439011"))
        mock_collection.find_one.return_value = {
            "_id": ObjectId("507f1f77bcf86cd799439011"),
            "filename": "test.wav",
            "transcript": "Complete workflow test",
            "created_at": datetime.utcnow(),
        }
        mock_collection.delete_one.return_value = Mock(deleted_count=1)

        mock_aws.upload_file_to_s3.return_value = (True, "test-bucket")
        mock_aws.start_transcription_job.return_value = {"JobName": "test-job"}
        mock_aws.wait_for_job_completion.return_value = {
            "TranscriptionJob": {"Transcript": {"TranscriptFileUri": "https://test.uri"}}
        }
        mock_aws.download_transcription_result.return_value = {"results": {}}
        mock_process.return_value = {"transcript": "Complete workflow test", "speakers": [], "duration": 10.0}

        # 1. Upload and transcribe
        response = client.post(
            "/transcribe",
            files={"file": ("test.wav", b"test audio content", "audio/wav")},
            data={"provider": "aws", "language": "en-US", "enable_diarization": "true"},
        )

        assert response.status_code == 200
        transcription_id = response.json()["id"]

        # 2. Get transcription details
        response = client.get(f"/transcription/{transcription_id}")
        assert response.status_code == 200
        assert response.json()["transcript"] == "Complete workflow test"

        # 3. Check in history
        mock_cursor = Mock()
        mock_cursor.sort.return_value = mock_cursor
        mock_cursor.limit.return_value = [mock_collection.find_one.return_value]
        mock_collection.find.return_value = mock_cursor

        response = client.get("/history")
        assert response.status_code == 200

        # 4. Delete transcription
        response = client.delete(f"/transcription/{transcription_id}")
        assert response.status_code == 200

    @patch("backend.main.collection")
    def test_multi_provider_comparison(self, mock_collection):
        """Test transcribing same file with different providers"""
        mock_collection.insert_one.return_value = Mock(inserted_id=ObjectId())

        providers = ["aws", "azure", "gcp"]
        results = []

        for provider in providers:
            with patch(f"backend.main.process_{provider}_transcription") as mock_process:
                mock_process.return_value = {"transcript": f"Test from {provider}", "speakers": [], "duration": 5.0}

                response = client.post(
                    "/transcribe",
                    files={"file": ("test.wav", b"test audio content", "audio/wav")},
                    data={"provider": provider, "language": "en-US"},
                )

                assert response.status_code == 200
                results.append(response.json())

        # Verify all providers processed successfully
        assert len(results) == 3
        assert all(r["provider"] in providers for r in results)

    @patch("backend.main.collection")
    def test_statistics_aggregation(self, mock_collection):
        """Test statistics aggregation across providers"""
        # Setup mock data
        mock_collection.count_documents.return_value = 150
        mock_collection.aggregate.return_value = [
            {"_id": "aws", "count": 75, "total_duration": 3000, "total_cost": 72.0},
            {"_id": "azure", "count": 50, "total_duration": 2000, "total_cost": 32.0},
            {"_id": "gcp", "count": 25, "total_duration": 1000, "total_cost": 18.0},
        ]
        mock_collection.find.return_value.sort.return_value.limit.return_value = [
            {"filename": f"recent_{i}.wav"} for i in range(5)
        ]

        response = client.get("/stats")
        assert response.status_code == 200

        stats = response.json()
        assert stats["total_transcriptions"] == 150

        # Verify cost calculations
        total_cost = sum(p["total_cost"] for p in stats["provider_statistics"])
        assert total_cost == 122.0  # 72 + 32 + 18

        # Verify provider distribution
        aws_stats = next(p for p in stats["provider_statistics"] if p["_id"] == "aws")
        assert aws_stats["count"] == 75
        assert aws_stats["count"] == stats["total_transcriptions"] / 2  # 50% of total


class TestErrorRecovery:
    """Test error recovery and resilience"""

    @patch("backend.main.aws_service")
    def test_s3_upload_retry(self, mock_aws):
        """Test retry logic for S3 upload failures"""
        # Simulate intermittent failure - upload_file_to_s3 returns tuple (success, bucket)
        mock_aws.upload_file_to_s3.side_effect = [(False, ""), (False, ""), (False, "")]

        response = client.post(
            "/transcribe",
            files={"file": ("test.wav", b"test audio content", "audio/wav")},
            data={"provider": "aws", "language": "en-US"},
        )

        # Should fail after retries exhausted
        assert response.status_code == 500

    @pytest.mark.skip(reason="Cleanup logic needs to be fixed in main code")
    @patch("backend.main.collection")
    @patch("backend.main.aws_service")
    def test_cleanup_on_failure(self, mock_aws, mock_collection):
        """Test resource cleanup on transcription failure"""
        mock_aws.upload_file_to_s3.return_value = (True, "test-bucket")
        mock_aws.start_transcription_job.side_effect = Exception("API Error")
        mock_aws.delete_file_from_s3.return_value = True

        response = client.post(
            "/transcribe",
            files={"file": ("test.wav", b"test audio content", "audio/wav")},
            data={"provider": "aws", "language": "en-US"},
        )

        assert response.status_code == 500
        # Verify cleanup was attempted
        mock_aws.delete_file_from_s3.assert_called()

    @patch("backend.main.mongo_client")
    def test_mongodb_reconnection(self, mock_mongo):
        """Test MongoDB reconnection after connection loss"""
        # Simulate connection loss and recovery
        mock_mongo.admin.command.side_effect = [Exception("Connection lost"), True]  # Reconnected

        # First check should fail
        response = client.get("/db/health")
        assert response.status_code == 503

        # Second check should succeed
        response = client.get("/db/health")
        assert response.status_code == 200


class TestPerformance:
    """Performance and load testing"""

    @patch("backend.main.collection")
    def test_large_file_handling(self, mock_collection):
        """Test handling of large audio files"""
        mock_collection.insert_one.return_value = Mock(inserted_id=ObjectId())

        # Create a large test file (10MB) with test pattern
        large_file = b"test " + b"0" * (10 * 1024 * 1024 - 5)

        with patch("backend.main.process_aws_transcription") as mock_process:
            mock_process.return_value = {
                "transcript": "Large file test",
                "speakers": [],
                "duration": 600.0,  # 10 minutes
            }

            response = client.post(
                "/transcribe",
                files={"file": ("large.wav", large_file, "audio/wav")},
                data={"provider": "aws", "language": "en-US"},
            )

            assert response.status_code == 200
            assert response.json()["duration"] == 600.0

    @patch("backend.main.collection")
    def test_history_with_large_dataset(self, mock_collection):
        """Test history endpoint with large dataset"""
        # Create 1000 mock records
        large_dataset = [
            {
                "_id": ObjectId(),
                "filename": f"file_{i}.wav",
                "created_at": datetime.utcnow() - timedelta(hours=i),
                "transcript": f"Transcript {i}",
            }
            for i in range(1000)
        ]

        mock_cursor = Mock()
        mock_cursor.sort.return_value = mock_cursor
        mock_cursor.limit.return_value = large_dataset[:50]  # Return first 50
        mock_collection.find.return_value = mock_cursor

        response = client.get("/history?limit=50")
        assert response.status_code == 200
        assert len(response.json()) == 50

    @patch("backend.main.collection")
    def test_concurrent_history_requests(self, mock_collection):
        """Test concurrent history requests"""
        mock_cursor = Mock()
        mock_cursor.sort.return_value = mock_cursor
        mock_cursor.limit.return_value = []
        mock_collection.find.return_value = mock_cursor

        # Simulate 10 concurrent requests
        import threading

        results = []

        def make_request():
            response = client.get("/history")
            results.append(response.status_code)

        threads = [threading.Thread(target=make_request) for _ in range(10)]
        for t in threads:
            t.start()
        for t in threads:
            t.join()

        # All requests should succeed
        assert all(status == 200 for status in results)
        assert len(results) == 10
